{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "deeplearningWithChainer.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/NaNkotsukan/deepLearningWithChainer/blob/master/deeplearningWithChainer.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "qFkUNbK2oNum",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 環境設定"
      ]
    },
    {
      "metadata": {
        "id": "y8KsUKjOoNun",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!apt -y install libcusparse8.0 libnvrtc8.0 libnvtoolsext1\n",
        "!ln -snf /usr/lib/x86_64-linux-gnu/libnvrtc-builtins.so.8.0 /usr/lib/x86_64-linux-gnu/libnvrtc-builtins.so\n",
        "!pip install cupy-cuda80 chainer matplotlib\n",
        "!nvidia-smi"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5f1nmtd9Q76_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# MNISTデータセットのクラス分類\n",
        "MNISTデータセットを用いてクラス分類をします．深い理解がなくても進められると思うので頑張っていきましょう．"
      ]
    },
    {
      "metadata": {
        "id": "QoGY31sioNur",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 深く知りたい?\n",
        "\n",
        "「ゼロから作るDeep Learning」って本おすすめ．\n",
        "\n",
        "#### 更に深くって?\n",
        "「パターン認識と機械学習」って本が凄いらしい．"
      ]
    },
    {
      "metadata": {
        "id": "-bsDFgyxoNus",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Chainerのインポート\n",
        "\n",
        "使うライブラリを読み込む．"
      ]
    },
    {
      "metadata": {
        "id": "Mg5A9-hfoNuv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Chainerは国産の機械学習ライブラリで全てPythonで書かれてるので中を見ることができる．\n",
        "\n",
        "公式ドキュメント：https://docs.chainer.org/en/stable/index.html\n"
      ]
    },
    {
      "metadata": {
        "id": "xdvqs3uUoNus",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from chainer import Chain, serializers, computational_graph\n",
        "from chainer import Variable as V\n",
        "import chainer.functions as F\n",
        "import chainer.links as L\n",
        "import chainer.computational_graph as C\n",
        "from chainer.optimizers import Adam, SGD\n",
        "import chainer\n",
        "\n",
        "# import pydot\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "from IPython.display import Image, display\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import cupy as cp\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "U2KEoze4oNuv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### データセットを読み込む\n",
        "\n",
        "MNISTデータセットをメモリ上に読み込む.\n",
        "\n",
        "50000枚の学習用データセットと10000枚のテスト用データセットを読み込む"
      ]
    },
    {
      "metadata": {
        "id": "JCaYUrCToNuw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train, test = chainer.datasets.get_mnist(ndim=2)\n",
        "trainX = train._datasets[0]\n",
        "trainT = train._datasets[1]\n",
        "testX = test._datasets[0]\n",
        "testT = test._datasets[1]\n",
        "\n",
        "print(trainX.shape)\n",
        "print(trainT.shape)\n",
        "print(testX.shape)\n",
        "print(testT.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dbFSFXUTB1Gs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def show_img(img, title):\n",
        "    fig = plt.figure(figsize=(15, 20))\n",
        "    for i in range(len(img)):\n",
        "        a = fig.add_subplot(1, len(img), i+1)\n",
        "        a.imshow(img[i])\n",
        "        plt.xlim((0, 28))\n",
        "        plt.ylim((28, 0))\n",
        "        plt.tick_params(labelbottom=False, labelleft=False)\n",
        "        plt.title(title[i], fontsize=15)\n",
        "        plt.grid()\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sMxbJi7VB_tS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "show_img(trainX[0:10], trainT[0:10])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SIKyFmtCoNu0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### ニューラルネットワーク\n",
        "\n",
        "まずはじめに二層の全結合層(Affine変換)のみで構成したニューラルネットワークを学習させてみる．"
      ]
    },
    {
      "metadata": {
        "id": "70fv1NNKoNu1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Model0(Chain):\n",
        "    def __init__(self):\n",
        "        super(Model0, self).__init__()\n",
        "        with self.init_scope():\n",
        "            self.l0 = L.Linear(784, 500)\n",
        "#           self.add_link(\"l0\", L.Linear(784, 500))     # このようにメタな書き方をすることも出来る．上と等価\n",
        "            self.l1 = L.Linear(500, 300)\n",
        "\n",
        "    def __call__(self, x):\n",
        "        h = self.l0(x)\n",
        "#       h = self[\"l0\"](x)       # このようにメタな書き方をすることも出来る．上と等価\n",
        "        h = F.relu(h)\n",
        "        h = self.l1(h)\n",
        "        return h"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "m7_K4gSMoNu7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 定義したモデルを学習させる\n",
        "### 学習の準備\n",
        "\n",
        "Optimizerはモデルの学習におけるパラメータを更新してくれるクラス．\n",
        "\n",
        "[optimizers](http://docs.chainer.org/en/stable/reference/optimizers.html#optimizers)にはSGD, RMSprop, AdaGrad，Adam，などいろいろあるけど今回はよく用いられるAdamを使う．\n"
      ]
    },
    {
      "metadata": {
        "id": "wZ7EE6qYoNu8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def test(model, x, t):\n",
        "    y = model(x)\n",
        "    loss = F.softmax_cross_entropy(y, t)\n",
        "    acc = F.accuracy(y, t)\n",
        "    return loss.data, acc.data\n",
        "\n",
        "def batch(model, optimizer, x, t):\n",
        "    y = model(x)\n",
        "    loss = F.softmax_cross_entropy(y, t)\n",
        "    model.cleargrads()\n",
        "    loss.backward()\n",
        "    optimizer.update()\n",
        "    return loss.data\n",
        "\n",
        "def training(model, epoch, batchsize, trainX, trainT, testX, testT):\n",
        "    optimizer = Adam()\n",
        "    optimizer.setup(model)\n",
        "    for i in range(epoch):\n",
        "        index = np.random.permutation(len(trainX))\n",
        "        for j in range(0, len(trainX), batchsize):\n",
        "            x = np.asarray(trainX[index[j:j+batchsize]]).astype(np.float32)\n",
        "            t = np.asarray(trainT[index[j:j+batchsize]])\n",
        "            loss = batch(model, optimizer, x, t)\n",
        "            if j%10000==0:\n",
        "                print(f\"epoch:{i:3d} batch:{j:6d} loss:{float(loss):0.4f}\")\n",
        "        x = np.asarray(testX).astype(np.float32)\n",
        "        t = np.asarray(testT)\n",
        "        loss, acc = test(model, x, t)\n",
        "        print(f\"epoch:{i:3d} testLoss:{float(loss):0.4f} testAccuracy:{float(acc):0.4f}\")\n",
        "    model.to_cpu()\n",
        "\n",
        "\n",
        "def training_GPU(model, epoch, batchsize, trainX, trainT, testX, testT):\n",
        "    model.to_gpu()\n",
        "    optimizer = Adam()\n",
        "    optimizer.setup(model)\n",
        "    for i in range(epoch):\n",
        "        index = np.random.permutation(len(trainX))\n",
        "        for j in range(0, len(trainX), batchsize):\n",
        "            x = cp.asarray(trainX[index[j:j+batchsize]]).astype(np.float32)\n",
        "            t = cp.asarray(trainT[index[j:j+batchsize]])\n",
        "            loss = batch(model, optimizer, x, t)\n",
        "            if j%10000==0:\n",
        "                print(f\"epoch:{i:3d} batch:{j:6d} loss:{float(loss):0.4f}\")\n",
        "        x = cp.asarray(testX).astype(np.float32)\n",
        "        t = cp.asarray(testT)\n",
        "        loss, acc = test(model, x, t)\n",
        "        print(f\"epoch:{i:3d} testLoss:{float(loss):0.4f} testAccuracy:{float(acc):0.4f}\")\n",
        "    model.to_cpu()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7MKFA14CoNu-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 学習を実行する\n",
        "epoch数，batchsizeを設定する．1epochとはデータセットを全て1通り学習することである．1epoch終えるとデータセットをシャッフルし次のepochに入る．batchsizeは1度に学習するデータの数のことである．"
      ]
    },
    {
      "metadata": {
        "id": "Rit-xqAIoNu-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "epoch = 2\n",
        "batchsize = 100\n",
        "model = Model0()\n",
        "training(model, epoch, batchsize, trainX, trainT, testX, testT)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "11qdyKS2KwaE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "result = model(testX[:100]).data.argmax(axis=1)\n",
        "for i in range(0, 30, 10):\n",
        "    show_img(testX[i:i+10], [f\"t:{testT[i+j]}  y:{result[i+j]}\" for j in range(10)])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kaYbaFVFoNu-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 精度の改善\n",
        "\n",
        "epoch数，batchsize，modelの層の数を変えてみよう．"
      ]
    },
    {
      "metadata": {
        "id": "nhbpmqnwoNvB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Model1(Chain):\n",
        "    def __init__(self):\n",
        "        super(Model1, self).__init__()\n",
        "        with self.init_scope():\n",
        "            self.l0 = L.Linear(784, 500)\n",
        "            self.l1 = L.Linear(500, 300)\n",
        "            self.l2 = L.Linear(300, 100)\n",
        "            self.l3 = L.Linear(100, 10)            \n",
        "\n",
        "    def __call__(self, x):\n",
        "        h = F.relu(self.l0(x))\n",
        "        h = F.relu(self.l1(h))\n",
        "        h = F.relu(self.l2(h))\n",
        "        h = self.l3(h)\n",
        "        return h"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iCE7FNK_HRY4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "epoch = 10\n",
        "batchsize = 100\n",
        "model = Model1()\n",
        "training_GPU(model, epoch, batchsize, trainX, trainT, testX, testT)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Tnlt_Yp0oNvZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 更に精度を上げる\n",
        "\n",
        "畳み込みニューラルネットワーク(CNN)を使用する．\n",
        "model0，model1では線形結合層のみでモデルを定義した．しかし深層学習の火付け役となったAlexNet登場以降，CNNが常用される．画像認識などの分野でとても力を発揮するので使ってみよう．"
      ]
    },
    {
      "metadata": {
        "id": "gvnTzi5ooNva",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Model2(Chain):\n",
        "    def __init__(self):\n",
        "        super(Model2, self).__init__()\n",
        "        with self.init_scope():\n",
        "            self.conv0 = L.Convolution2D(1, 32, ksize=3)\n",
        "            self.conv1 = L.Convolution2D(32, 32, ksize=3)\n",
        "            self.conv2 = L.Convolution2D(32, 32, ksize=3)\n",
        "            self.conv3 = L.Convolution2D(32, 32, ksize=3)\n",
        "            self.l0 = L.Linear(2048 , 10)\n",
        "\n",
        "    def __call__(self, x):\n",
        "        h = F.reshape(x, (-1, 1, 28, 28))\n",
        "        h = F.relu(self.conv0(h))\n",
        "        h = F.relu(self.conv1(h))\n",
        "        h = F.max_pooling_2d(h, 2)\n",
        "        h = F.relu(self.conv2(h))\n",
        "        h = F.relu(self.conv3(h))\n",
        "        h = self.l0(h)\n",
        "        return h"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "C5erUGl6oNve",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "epoch = 10\n",
        "batchsize = 100\n",
        "model = Model2()\n",
        "training_GPU(model, epoch, batchsize, trainX, trainT, testX, testT)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aYVegyj3bxbq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###もっと精度上げたい?\n",
        "#### さらに深く\n",
        "https://arxiv.org/abs/1512.03385\n",
        "#### もっと深く\n",
        "https://arxiv.org/abs/1806.05393"
      ]
    }
  ]
}