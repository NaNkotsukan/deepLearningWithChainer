{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DCGANwithChainer_ipynb_.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/NaNkotsukan/deepLearningWithChainer/blob/master/DCGANwithChainer_ipynb_.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "jznsDrSjfk99",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 環境設定"
      ]
    },
    {
      "metadata": {
        "id": "nHwU0tNpfj1s",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!apt -y install libcusparse8.0 libnvrtc8.0 libnvtoolsext1\n",
        "!ln -snf /usr/lib/x86_64-linux-gnu/libnvrtc-builtins.so.8.0 /usr/lib/x86_64-linux-gnu/libnvrtc-builtins.so\n",
        "!pip install cupy-cuda80 chainer matplotlib\n",
        "!nvidia-smi"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "503YZqYoN3p_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# GANに依る画像生成\n",
        "GAN(Generative adversarial networks)は複数のネットワークを競わせて学習し画像の生成などを行うモデルである．\n",
        "提唱論文：https://arxiv.org/abs/1406.2661\n",
        "今回使うモデルはDCGAN( https://arxiv.org/abs/1511.06434 )である．"
      ]
    },
    {
      "metadata": {
        "id": "TV6YBjIjPIcv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from chainer import Chain, serializers, computational_graph\n",
        "from chainer import Variable as V\n",
        "import chainer.functions as F\n",
        "import chainer.links as L\n",
        "import chainer.computational_graph as C\n",
        "from chainer.optimizers import Adam, SGD\n",
        "import chainer\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "from IPython.display import Image, display\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import cupy as cp\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xuyGfuDKOj9P",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train, test = chainer.datasets.get_mnist(ndim=3)\n",
        "trainX = train._datasets[0]\n",
        "trainT = train._datasets[1]\n",
        "testX = test._datasets[0]\n",
        "testT = test._datasets[1]\n",
        "\n",
        "print(trainX.shape)\n",
        "print(testX.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mROTQHsoWRAr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def show_img(img, title=None):\n",
        "    fig = plt.figure(figsize=(15, 20))\n",
        "    for i in range(len(img)):\n",
        "        if img[i].ndim==3: x = img[i][0]\n",
        "        else: x = img[i]\n",
        "        a = fig.add_subplot(1, len(img), i+1)\n",
        "        a.imshow(x)\n",
        "        plt.xlim((0, 28))\n",
        "        plt.ylim((28, 0))\n",
        "        plt.tick_params(labelbottom=False, labelleft=False)\n",
        "        if title != None:\n",
        "            plt.title(title[i], fontsize=15)\n",
        "        plt.grid()\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "x8bNkwtfN3qA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## DCGAN\n",
        "DCGANではGeneratorとDiscriminatorの2つのモデルを使う．"
      ]
    },
    {
      "metadata": {
        "id": "_IYXQoRCO9BC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Generator(chainer.Chain):\n",
        "    def __init__(self, n_hidden=100):\n",
        "        super(Generator, self).__init__()\n",
        "        with self.init_scope():\n",
        "            self.l0 = L.Linear(in_size=n_hidden, out_size=512*9, initialW=w)\n",
        "            self.deconv0 = L.Deconvolution2D(in_channels=512, out_channels=256, ksize=2, stride=2, pad=1)\n",
        "            self.deconv1 = L.Deconvolution2D(256, 128, 2, 2, 1)\n",
        "            self.deconv2 = L.Deconvolution2D(128, 64,  2, 2, 1)\n",
        "            self.deconv3 = L.Deconvolution2D(64,  1,   3, 3, 1)\n",
        "            self.bn0 = L.BatchNormalization(512)\n",
        "            self.bn1 = L.BatchNormalization(256)\n",
        "            self.bn2 = L.BatchNormalization(128)\n",
        "            self.bn3 = L.BatchNormalization(64)\n",
        "\n",
        "\n",
        "    def __call__(self, z):\n",
        "        h = self.l0(z)\n",
        "        h = F.reshape(h, (-1, 512, 3, 3))\n",
        "        h = F.relu(self.bn0(h))\n",
        "        h = F.relu(self.bn1(self.deconv0(h)))\n",
        "        h = F.relu(self.bn2(self.deconv1(h)))\n",
        "        h = F.relu(self.bn3(self.deconv2(h)))\n",
        "        x = F.sigmoid(self.deconv3(h))\n",
        "        return x\n",
        "\n",
        "\n",
        "class Discriminator(chainer.Chain):\n",
        "    def __init__(self):\n",
        "        super(Discriminator, self).__init__()\n",
        "        with self.init_scope():\n",
        "            self.conv0 = L.Convolution2D(in_channels=1, out_channels=64, ksize=3, stride=3, pad=1)\n",
        "            self.conv1 = L.Convolution2D(64, 128, 2, 2, 1)\n",
        "            self.conv2 = L.Convolution2D(128, 256, 2, 2, 1)\n",
        "            self.conv3 = L.Convolution2D(256, 512, 2, 2, 1)\n",
        "            self.l0 = L.Linear(in_size=None, out_size=2)\n",
        "            self.bn0 = L.BatchNormalization(128)\n",
        "            self.bn1 = L.BatchNormalization(256)\n",
        "            self.bn2 = L.BatchNormalization(512)\n",
        "\n",
        "\n",
        "    def __call__(self, x):\n",
        "        h = F.leaky_relu(self.conv0(x))\n",
        "        h = F.leaky_relu(self.bn0(self.conv1(h)))\n",
        "        h = F.leaky_relu(self.bn1(self.conv2(h)))\n",
        "        h = F.leaky_relu(self.bn2(self.conv3(h)))\n",
        "        y = self.l0(h)\n",
        "\n",
        "        return y\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZgaTyZzJPUOS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Training:\n",
        "    def __init__(self, GPU=True):\n",
        "        self.generator = Generator()\n",
        "        self.discriminator = Discriminator()\n",
        "        self.gen_opt = Adam(beta1=0.5)\n",
        "        self.dis_opt = Adam(beta1=0.5)\n",
        "        self.gen_opt.setup(self.generator)\n",
        "        self.dis_opt.setup(self.discriminator)\n",
        "        self.generator.to_gpu()\n",
        "        self.discriminator.to_gpu()\n",
        "\n",
        "    def test(self, z):\n",
        "        y = self.generator(z).data.get()\n",
        "        show_img(y)\n",
        "\n",
        "    def batch(self, z, x):\n",
        "        fakeimg = self.generator(z)\n",
        "        y_fake = self.discriminator(fakeimg)\n",
        "        y_real = self.discriminator(x)\n",
        "        \n",
        "        gen_loss = F.softmax_cross_entropy(y_fake, cp.ones(len(z), dtype=cp.int8))\n",
        "        \n",
        "        dis_y = F.concat([y_fake, y_real], axis=0)\n",
        "        dis_t = cp.hstack([cp.zeros(len(z), dtype=cp.int8), cp.ones(len(x), dtype=cp.int8)])\n",
        "        dis_loss = F.softmax_cross_entropy(dis_y, dis_t)\n",
        "        \n",
        "\n",
        "        \n",
        "        self.generator.cleargrads()\n",
        "        gen_loss.backward()\n",
        "        self.gen_opt.update()\n",
        "        \n",
        "        self.discriminator.cleargrads()\n",
        "        dis_loss.backward()\n",
        "        self.dis_opt.update()\n",
        "        \n",
        "        return gen_loss.data, dis_loss.data\n",
        "        \n",
        "        \n",
        "\n",
        "    def training(self, epoch, batchsize):\n",
        "        test_z = cp.random.uniform(-1, 1, (10, 100, 1, 1)).astype(cp.float32)\n",
        "        for i in range(epoch):\n",
        "            index = np.random.permutation(len(trainX))\n",
        "            for j in range(0, len(trainX), batchsize):\n",
        "                x = cp.asarray(trainX[index[j:j+batchsize]]).astype(np.float32).reshape(batchsize, 1, 28, 28)\n",
        "                z = cp.random.uniform(-1, 1, (batchsize, 100, 1, 1)).astype(cp.float32)\n",
        "                gen_loss, dis_loss = self.batch(z, x)\n",
        "                if j%10000==0:\n",
        "                    print(f\"epoch:{i:3d} batch:{j:6d} gen_loss:{float(gen_loss):0.4f} dis_loss:{float(dis_loss):0.4f}\")\n",
        "            self.test(test_z)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oXBrWR5NYovN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "hoge = Training()\n",
        "hoge.training(200, 50)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}